{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import wave\n",
    "import sys\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_to_mfcc(files):\n",
    "    audio, sample_rate = librosa.load('test/'+files)\n",
    "    audio = normalize_audio(audio)\n",
    "    mfccs = librosa.feature.mfcc(audio, sample_rate)\n",
    "    delta = librosa.feature.delta(mfccs)\n",
    "    delta_delta = librosa.feature.delta(mfccs, order = 2)\n",
    "    return mfccs, delta, delta_delta\n",
    "\n",
    "def normalize_audio(audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "def plot_mfcc(mfccs):\n",
    "    librosa.display.specshow(mfccs, x_axis = 'time')\n",
    "    plt.colorbar()\n",
    "    plt.title('Normalized MFCC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return 0\n",
    "\n",
    "def plot_wav(files):\n",
    "    audio, sample_rate = librosa.load('test/'+files)\n",
    "    audio = normalize_audio(audio)\n",
    "    plt.figure(figsize=(15,4))\n",
    "    plt.plot(np.linspace(0, len(audio) / sample_rate, num=len(audio)), audio)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = hyenas    1 = lions\n",
    "mfccs = []\n",
    "deltas = []\n",
    "delta_deltas = []\n",
    "label = []\n",
    "for file in os.listdir('test/'):\n",
    "    Mfcc, Delta, Delta_delta = wav_to_mfcc(file)\n",
    "    mfccs.append(torch.from_numpy(Mfcc))\n",
    "    deltas.append(torch.from_numpy(Delta))\n",
    "    delta_deltas.append(torch.from_numpy(Delta_delta))\n",
    "    if 'lion' in file:\n",
    "        label.append(1)\n",
    "    else:\n",
    "        label.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have obtained the following for our input data:\n",
    "1. **mfccs[i]**: the mel-frequency cepstrum coefficients for a single audio file indexed at *i*\n",
    "2. **deltas[i]**: the first derivative of the mfccs \n",
    "3. **delta_deltas[i]**: the second derivative of the mfccs\n",
    "\n",
    "and our associated label:\n",
    "1. **label[i]**: the audio file indexed at *i* will be 1 if it is a lion and 0 if it is a hyena"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, mfcc_total):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv_mfcc = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(mfcc_total, 3), stride=1)\n",
    "        self.conv_delta = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(mfcc_total, 3), stride=1)\n",
    "        self.conv_delta_delta = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=(mfcc_total, 3), stride=1)\n",
    "\n",
    "        self.conv_1 = nn.Conv2d(in_channels=1, out_channels= 1, kernel_size=(3, 10), stride= 3)\n",
    "        self.conv_2 = nn.Conv2d(in_channels=1, out_channels= 1, kernel_size=(1, 5), stride = 1)\n",
    "        self.fc1 = nn.Linear(14, 10)\n",
    "        self.fc2 = nn.Linear(10, 1)\n",
    " \n",
    "\n",
    "    def forward(self, mfcc, delta, delta_delta):\n",
    "        # Compressing features into 3x300 matrix\n",
    "        mfcc_features = self.conv_mfcc(mfcc)\n",
    "        delta_features = self.conv_delta(delta)\n",
    "        delta_delta_features = self.conv_delta_delta(delta_delta)\n",
    "        features = torch.cat((mfcc_features, delta_features, delta_delta_features), 2)\n",
    "        features = F.relu(self.conv_1(features))\n",
    "        features = F.relu(self.conv_2(features))\n",
    "        features = features.view(-1, 14)\n",
    "        features = self.fc1(features).squeeze(0)\n",
    "        features = torch.sigmoid(self.fc2(features))\n",
    "    \n",
    "        return features\n",
    "    \n",
    "def load_model(lr, seed, mfcc_total):\n",
    "    torch.manual_seed(seed)\n",
    "    model = Net(mfcc_total)\n",
    "    loss_function = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    return model#, loss_function, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 66])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfccs[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### SET HYPERPARAMETERS HERE ######\n",
    "lr = 0.1\n",
    "seed = 42\n",
    "mfcc_total = 13\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_test():\n",
    "    torch.manual_seed(seed)\n",
    "    model = load_model(lr, seed, mfcc_total)\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(mfccs)):\n",
    "            mfcc = mfccs[i][1: mfcc_total + 1][:, :65].unsqueeze(0).unsqueeze(0)\n",
    "            delta = deltas[i][1: mfcc_total + 1][:, :65].unsqueeze(0).unsqueeze(0)\n",
    "            delta_delta = delta_deltas[i][1: mfcc_total + 1][:, :65].unsqueeze(0).unsqueeze(0)\n",
    "            model(mfcc, delta, delta_delta)\n",
    "            ###### FILL THIS OUT ######\n",
    "            \n",
    "        \n",
    "main_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
